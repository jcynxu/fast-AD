"""
ReplayBuffer: a FIFO buffer for storing synthetic samples (paper Sec. 3.5).
"""

from collections import deque
import random
import torch


class ReplayBuffer:
    """
    Dynamic buffer mechanism (paper Sec. 3.5).
    
    A FIFO (First-In-First-Out) buffer for storing synthetic samples.
    This ensures the student is trained on the most recent synthesis distribution.
    
    Policy:
    - Push: each synthesis cycle pushes a batch of rectified images x_syn into the buffer
    - Pop: when capacity is exceeded, the oldest samples are discarded automatically
    """
    def __init__(self, max_size: int = 4096):
        """
        Args:
            max_size: buffer capacity |B|
        """
        # `deque(maxlen=...)` implements FIFO automatically:
        # when capacity is exceeded, the oldest items are dropped.
        self.buffer = deque(maxlen=max_size)
        self.max_size = max_size
    
    def push(self, images: torch.Tensor, targets: torch.Tensor):
        """
        Push (images, labels) into the buffer.
        
        Paper: in each synthesis cycle, a batch of rectified images x_syn
        (generated by Fast-AD via Eq. 7) is pushed into B.
        
        Args:
            images: [B, C, H, W] tensor (rectified synthetic images x_syn)
            targets: [B] tensor (labels)
        """
        # Store samples individually to support random sampling later.
        for i in range(images.size(0)):
            self.buffer.append((images[i].cpu().clone(), targets[i].cpu().clone()))
    
    def sample(self, batch_size: int) -> tuple:
        """
        Randomly sample a batch from the buffer (for student updates).
        
        Paper: in the distillation phase, sample synthetic images x ~ B.
        
        Args:
            batch_size: batch size
            
        Returns:
            images: [B, C, H, W] tensor
            targets: [B] tensor
        """
        if len(self.buffer) == 0:
            raise ValueError("Buffer is empty, cannot sample")
        
        # Random sampling encourages diversity during student training.
        batch = random.sample(self.buffer, min(len(self.buffer), batch_size))
        images = torch.stack([b[0] for b in batch])
        targets = torch.stack([b[1] for b in batch])
        return images, targets
    
    def __len__(self):
        """Return current buffer size."""
        return len(self.buffer)
    
    def is_full(self) -> bool:
        """Return True if buffer is at capacity."""
        return len(self.buffer) >= self.max_size
    
    def clear(self):
        """Clear all items."""
        self.buffer.clear()

