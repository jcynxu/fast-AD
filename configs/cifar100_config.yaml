# Fast-AD Configuration for CIFAR-100

# Distillation Settings
distillation:
  teacher_arch: "resnet34"          # Teacher 网络架构
  student_arch: "resnet18"          # Student 网络架构
  num_classes: 100                  # 类别数 (CIFAR-100)
  image_size: [32, 32]              # 图像尺寸 [H, W]
  epochs: 200                       # 训练轮数
  buffer_size: 4096                 # ReplayBuffer 最大容量
  lr: 0.1                           # 初始学习率
  milestones: [100, 150]            # 学习率衰减的 epoch
  synthesis_batch_size: 64          # 每个 epoch 合成的图像数量
  train_batch_size: 64              # 训练批次大小
  train_iterations: 100             # 每个 epoch 的训练迭代次数
  kd_temperature: 4.0                # 知识蒸馏温度 τ_kd (公式 9)
  
  # 预训练模型路径 (可选)
  # teacher_checkpoint: "path/to/teacher.pth"
  # diffusion_checkpoint: "path/to/diffusion.pth"

# Fast-AD Algorithm Parameters
fast_ad:
  lambda_max: 1.5                   # 最大引导强度
  eta: 0.1                          # 梯度缩放因子 (Gradient Scaling Factor)
  tau_ent: 0.4                      # 熵阈值 (CIFAR-100为0.4, ImageNet为0.6)
  k_sigmoid: 10.0                   # Sigmoid 的陡峭程度
  ddim_steps: 50                    # DDIM 采样步数 (20x 加速)
  xi: 1e-6                          # 梯度归一化时的数值稳定常数
  gamma: 1.0                        # CE Loss 的权重
  T: 1000                           # 原始扩散模型的总步数

